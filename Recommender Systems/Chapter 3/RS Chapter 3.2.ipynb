{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86916729",
   "metadata": {},
   "source": [
    "# Chapter 3 Part 2<br>Parameter Optimization with Surprise\n",
    "## Dawei Wang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9057736",
   "metadata": {},
   "source": [
    "For this part you will experiment with parameter tuning for recommender systems implemented in Surprise. You will use the \"review.csv\" file from Yelp Core 5 distribution which includes ratings by users on various business establishments. The Yelp Core 5 data set is about 140k ratings, but it is fairly sparse (99.7%). Every user has rated at least five establishments and every establishment has at least five ratings. This data set is based on the Yelp challenge data set: https://www.kaggle.com/c/yelp-recsys-2013.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270c2858",
   "metadata": {},
   "source": [
    "Pick three algorithms that are implemented in Surprise.\n",
    "\n",
    "One neighborhood algorithm from:\n",
    "\n",
    "    * KNNWithMeans: Item or User\n",
    "    * KNNWithZScore: Item or User\n",
    "    * KNNBaseline: Item or User\n",
    "\n",
    "Two model-based algorithms from:\n",
    "\n",
    "    * SVD\n",
    "    * SVDpp\n",
    "    * NMF\n",
    "    * SlopeOne\n",
    "    * CoClustering\n",
    "\n",
    "Using the Yelp Core 5 data set, tune each algorithm to achieve the best performance on the RMSE metric.\n",
    "\n",
    "Note that there are quite a few parameters for some algorithms. Keep careful notes about what parameters you tried and the results that you got. The GridSearchCV method in Surprise can be useful for this purpose. You do not need to include your code and full outputs for parameter tuning, but you'll need to submit a separate report detailing what you tried (see below).\n",
    "\n",
    "After tuning your algorithm and determining the best parameters for each algorithm, create a Jupyter notebook showing a 5-fold CV comparison using the best parameters for each. Include a plot comparing the RMSE values.\n",
    "\n",
    "Important Note: A better experimental methodology (which we are not using here) would be to hold out a validation set for evaluation and tune the algorithms on the training portion of the data. This is the proper evaluation methodology that you should use in more realistic situations (including the class project).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "73720aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version list\n",
      "\n",
      "python 3.9.7\n",
      "numpy 1.22.2\n",
      "pandas 1.3.5\n",
      "scipy 1.7.3\n",
      "seaborn 0.11.2\n",
      "matplotlib 3.5.1\n",
      "nltk 3.7\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk      \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from matplotlib import pyplot as plt\n",
    "from platform import python_version\n",
    "from scipy.spatial.distance import cosine, correlation\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "pd.set_option('max_columns',200)\n",
    "pd.set_option('display.precision',2)\n",
    "\n",
    "print('Version list\\n')\n",
    "print('python',python_version())\n",
    "print(np.__name__, np.__version__)\n",
    "print(pd.__name__, pd.__version__)\n",
    "print(sp.__name__, sp.__version__)\n",
    "print(sns.__name__, sns.__version__)\n",
    "print(matplotlib.__name__, matplotlib.__version__)\n",
    "print(nltk.__name__, nltk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f43ccc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader, accuracy\n",
    "from surprise import KNNBaseline, KNNWithMeans, KNNWithZScore,SVD, SVDpp, NMF, SlopeOne, SVDpp, CoClustering\n",
    "from surprise.model_selection import cross_validate, GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ab01a7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/daweiwang/Desktop/CSC 577/Assignments')\n",
    "df = pd.read_csv('review.csv',header=None)\n",
    "df = df.rename(columns ={0:'u_id',1:'b_id',2:'ratings'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdab742e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u_id</th>\n",
       "      <th>b_id</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141449</th>\n",
       "      <td>14909</td>\n",
       "      <td>1790</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141450</th>\n",
       "      <td>13002</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141451</th>\n",
       "      <td>10521</td>\n",
       "      <td>498</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141452</th>\n",
       "      <td>15032</td>\n",
       "      <td>3315</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141453</th>\n",
       "      <td>10922</td>\n",
       "      <td>225</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141454 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         u_id  b_id  ratings\n",
       "0       10000     0        5\n",
       "1       10001     1        5\n",
       "2       10002     2        5\n",
       "3       10003     3        4\n",
       "4       10004     4        5\n",
       "...       ...   ...      ...\n",
       "141449  14909  1790        5\n",
       "141450  13002   154        1\n",
       "141451  10521   498        3\n",
       "141452  15032  3315        2\n",
       "141453  10922   225        3\n",
       "\n",
       "[141454 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ac8992b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating Scale\n",
      "Max: 5\n",
      "Min: 1\n"
     ]
    }
   ],
   "source": [
    "print('Rating Scale')\n",
    "print('Max:',df.ratings.max())\n",
    "print('Min:',df.ratings.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c32185b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating_scale 1-5\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "# Load data \n",
    "data = Dataset.load_from_df(df[['u_id','b_id','ratings']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6e8987de",
   "metadata": {},
   "outputs": [],
   "source": [
    "knnbasic_cv = cross_validate(KNNBaseline(), data, cv=5, n_jobs=5, verbose=False)\n",
    "knnmeans_cv = cross_validate(KNNWithMeans(), data, cv=5, n_jobs=5, verbose=False)\n",
    "knnzscore_cv = cross_validate(KNNWithZScore(), data, cv=5, n_jobs=5, verbose=False)\n",
    "svd_cv = cross_validate(SVD(), data, cv=5, n_jobs=5, verbose=False)\n",
    "svdpp_cv = cross_validate(SVDpp(), data, cv=5, n_jobs=5, verbose=False)\n",
    "nmf_cv = cross_validate(NMF(), data, cv=5, n_jobs=5, verbose=False)\n",
    "slope_cv = cross_validate(SlopeOne(), data, cv=5, n_jobs=5, verbose=False)\n",
    "cocluster_cv = cross_validate(CoClustering(), data, cv=5, n_jobs=5, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9383bd7",
   "metadata": {},
   "source": [
    "## Get the general idea of performances of all algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f3e924de",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = pd.DataFrame(columns=['Algorithm','RMSE'])\n",
    "algo=[knnbasic_cv, knnmeans_cv, knnzscore_cv, svd_cv, svdpp_cv, nmf_cv, slope_cv, cocluster_cv]\n",
    "name = ['KNN Baseline', 'KNN Means', 'KNN Zscore', 'SVD', 'SVD++', 'NMF', 'Slope One', 'Coclustering']\n",
    "for i in range(len(algo)):\n",
    "    RMSE.loc[i]=[name[i],algo[i]['test_rmse'].mean()]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ef963b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN Baseline</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Means</td>\n",
       "      <td>1.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN Zscore</td>\n",
       "      <td>1.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVD</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVD++</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NMF</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Slope One</td>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Coclustering</td>\n",
       "      <td>1.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Algorithm  RMSE\n",
       "0  KNN Baseline  1.06\n",
       "1     KNN Means  1.09\n",
       "2    KNN Zscore  1.09\n",
       "3           SVD  1.02\n",
       "4         SVD++  1.02\n",
       "5           NMF  1.12\n",
       "6     Slope One  1.11\n",
       "7  Coclustering  1.09"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0896d742",
   "metadata": {},
   "source": [
    "### We can see the best perfomance was from SVD and SVD++  \n",
    "### Next, try grid search on these two algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dd5f33bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_param_grid = {'n_factors': [60,100,140],\n",
    "                  'n_epochs': [5, 15, 25], \n",
    "                  'lr_all': [0.001, 0.005, 0.009],\n",
    "                  'reg_all': [0.2, 0.4, 0.6]}\n",
    "# epochs The number of iteration of the SGD procedure\n",
    "# lr_all: The learning rate for all parameters. Default is 0.005.\n",
    "# reg_all: The regularization term for all parameters. Default is 0.02.\n",
    "# Complexity O(n ^3)\n",
    "\n",
    "svdpp = GridSearchCV(SVDpp, svd_param_grid, measures=['rmse'], cv=3, n_jobs=5)\n",
    "svdpp.fit(data)\n",
    "\n",
    "svd = GridSearchCV(SVD, svd_param_grid, measures=['rmse'], cv=3, n_jobs=5)\n",
    "svd.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c2c18c",
   "metadata": {},
   "source": [
    "### The best result for these two algorithms listed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e92027c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0136\n",
      "{'n_factors': 60, 'n_epochs': 25, 'lr_all': 0.005, 'reg_all': 0.2}\n"
     ]
    }
   ],
   "source": [
    "print(round(svd.best_score['rmse'], 4))\n",
    "print(svd.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ddca039e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0193\n",
      "{'n_factors': 60, 'n_epochs': 25, 'lr_all': 0.005, 'reg_all': 0.2}\n"
     ]
    }
   ],
   "source": [
    "print(round(svdpp.best_score['rmse'], 4))\n",
    "print(svdpp.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d2cf1b",
   "metadata": {},
   "source": [
    "## Manual Search\n",
    "### To avoid long waiting and accident interruptions, here I tried to split the dataset and use combinations of parameters to get the best ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6fe133f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671c5265",
   "metadata": {},
   "source": [
    "### The parameter sets were based on the grid search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f75d71f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0206\n",
      "RMSE: 1.0209\n",
      "RMSE: 1.0226\n",
      "RMSE: 1.0155\n",
      "RMSE: 1.0150\n",
      "RMSE: 1.0164\n",
      "RMSE: 1.0141\n",
      "RMSE: 1.0129\n",
      "RMSE: 1.0143\n",
      "RMSE: 1.0170\n",
      "RMSE: 1.0179\n",
      "RMSE: 1.0195\n",
      "RMSE: 1.0132\n",
      "RMSE: 1.0140\n",
      "RMSE: 1.0146\n",
      "RMSE: 1.0142\n",
      "RMSE: 1.0130\n",
      "RMSE: 1.0138\n",
      "RMSE: 1.0160\n",
      "RMSE: 1.0163\n",
      "RMSE: 1.0174\n",
      "RMSE: 1.0141\n",
      "RMSE: 1.0133\n",
      "RMSE: 1.0142\n",
      "RMSE: 1.0159\n",
      "RMSE: 1.0129\n",
      "RMSE: 1.0137\n",
      "RMSE: 1.0204\n",
      "RMSE: 1.0215\n",
      "RMSE: 1.0233\n",
      "RMSE: 1.0149\n",
      "RMSE: 1.0155\n",
      "RMSE: 1.0167\n",
      "RMSE: 1.0150\n",
      "RMSE: 1.0142\n",
      "RMSE: 1.0145\n",
      "RMSE: 1.0177\n",
      "RMSE: 1.0182\n",
      "RMSE: 1.0193\n",
      "RMSE: 1.0144\n",
      "RMSE: 1.0139\n",
      "RMSE: 1.0154\n",
      "RMSE: 1.0152\n",
      "RMSE: 1.0130\n",
      "RMSE: 1.0141\n",
      "RMSE: 1.0162\n",
      "RMSE: 1.0168\n",
      "RMSE: 1.0173\n",
      "RMSE: 1.0139\n",
      "RMSE: 1.0131\n",
      "RMSE: 1.0143\n",
      "RMSE: 1.0157\n",
      "RMSE: 1.0129\n",
      "RMSE: 1.0139\n",
      "RMSE: 1.0214\n",
      "RMSE: 1.0214\n",
      "RMSE: 1.0231\n",
      "RMSE: 1.0166\n",
      "RMSE: 1.0159\n",
      "RMSE: 1.0175\n",
      "RMSE: 1.0145\n",
      "RMSE: 1.0136\n",
      "RMSE: 1.0148\n",
      "RMSE: 1.0188\n",
      "RMSE: 1.0179\n",
      "RMSE: 1.0201\n",
      "RMSE: 1.0147\n",
      "RMSE: 1.0140\n",
      "RMSE: 1.0152\n",
      "RMSE: 1.0154\n",
      "RMSE: 1.0135\n",
      "RMSE: 1.0136\n",
      "RMSE: 1.0167\n",
      "RMSE: 1.0167\n",
      "RMSE: 1.0178\n",
      "RMSE: 1.0142\n",
      "RMSE: 1.0132\n",
      "RMSE: 1.0143\n",
      "RMSE: 1.0161\n",
      "RMSE: 1.0135\n",
      "RMSE: 1.0137\n"
     ]
    }
   ],
   "source": [
    "n_factors = [45,60,75]\n",
    "n_epochs = [20, 25, 30]\n",
    "lr_all = [0.003, 0.005, 0.007]\n",
    "reg_all = [0.1, 0.2, 0.3]\n",
    "# parameters = 3^4 =81\n",
    "from itertools import product\n",
    "val = [n_factors,n_epochs,lr_all,reg_all]\n",
    "para = []\n",
    "acc = []\n",
    "for i in product(*val):\n",
    "    para.append(i)\n",
    "    algo = SVD(n_factors = i[0], n_epochs = i[1], lr_all=i[2], reg_all=i[3] )\n",
    "    algo.fit(train)\n",
    "    pred = algo.test(test)\n",
    "    acc.append(accuracy.rmse(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff8f9d0",
   "metadata": {},
   "source": [
    "### The best  RMSE is 1.0129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d8c0eeb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0128613232314272"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "722fb75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = para[acc.index(min(acc))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6e1733",
   "metadata": {},
   "source": [
    "### Here we can see, the best parameter set gives Mean RMSE 1.0144 on 5-fold cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f61e7011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0225  1.0153  1.0082  1.0142  1.0118  1.0144  0.0047  \n",
      "Fit time          3.71    3.54    3.45    3.88    3.63    3.64    0.15    \n",
      "Test time         0.08    0.15    0.08    0.16    0.08    0.11    0.04    \n"
     ]
    }
   ],
   "source": [
    "algo = SVD(n_factors = best[0], n_epochs = best[1], lr_all = best[2], reg_all = best[3] )\n",
    "\n",
    "SVD_best = cross_validate(algo, data, measures=['RMSE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb07642",
   "metadata": {},
   "source": [
    "### Then Try the same thing with SVD++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5f2526eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_factors = [45,60,75]\n",
    "n_epochs = [10, 15, 20]\n",
    "lr_all = [0.009,0.011,0.013]\n",
    "reg_all = [0.1, 0.2, 0.3]\n",
    "# parameters = 3^4 =81\n",
    "from itertools import product\n",
    "val = [n_factors,n_epochs,lr_all,reg_all]\n",
    "para = []\n",
    "acc = []\n",
    "for i in product(*val):\n",
    "    para.append(i)\n",
    "    algo = SVDpp(n_factors = i[0], n_epochs = i[1], lr_all=i[2], reg_all=i[3] )\n",
    "    algo.fit(train)\n",
    "    pred = algo.test(test)\n",
    "    acc.append(accuracy.rmse(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3b4c3d",
   "metadata": {},
   "source": [
    "### The best RMSE for SVD++ is 1.0164"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4d9437e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0163515956283986"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bae86591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 20, 0.009, 0.2)\n"
     ]
    }
   ],
   "source": [
    "best = para[acc.index(min(acc))]\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d85e9d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = SVDpp(n_factors = best[0], n_epochs = best[1], lr_all = best[2], reg_all = best[3] )\n",
    "\n",
    "SVDpp_best = cross_validate(algo, data, measures=['RMSE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30539a78",
   "metadata": {},
   "source": [
    "Evaluating RMSE of algorithm SVDpp on 5 split(s).\n",
    "\n",
    "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
    "RMSE (testset)    1.0208  1.0151  1.0070  1.0123  1.0187  1.0148  0.0049  \n",
    "Fit time          79.54   79.87   79.89   80.12   80.61   80.01   0.35    \n",
    "Test time         0.71    0.73    0.85    0.73    0.93    0.79    0.09 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0d7af3",
   "metadata": {},
   "source": [
    "### The best RMSE for SVD++ is 1.0148 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43164319",
   "metadata": {},
   "source": [
    "### For KNN, compare all three algorithms (KNN Baseline, KNN with means, KNN with Z-score) with different k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eceba112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.3212\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.3135\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.3251\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.1844\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.1942\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.2067\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.1353\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.1501\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.1601\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.1100\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.1269\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.1355\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0953\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.1137\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.1221\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0860\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.1052\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.1134\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0806\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.1004\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.1085\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0763\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0965\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.1043\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0736\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0939\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.1017\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0706\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0911\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0987\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0691\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0897\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0971\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0679\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0885\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0958\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0664\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0871\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0943\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0655\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0863\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0932\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0649\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0857\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0925\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0641\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0850\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0918\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0634\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0843\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0911\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0627\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0837\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0904\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0623\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0833\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0900\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0619\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0829\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0897\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0616\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0825\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0892\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0614\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0824\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0891\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0611\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0821\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0888\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0608\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0818\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0884\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0607\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0817\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0883\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0604\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0814\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0880\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0603\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0813\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0880\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0602\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0812\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0878\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0601\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0812\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0878\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0601\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0811\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0878\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0600\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0810\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0877\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0599\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0809\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0875\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0598\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0808\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0874\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0597\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0807\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0873\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0596\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0807\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0873\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0596\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0806\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0872\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0596\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0806\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0872\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0595\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0805\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0871\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0594\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0804\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0871\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0594\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0804\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0870\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0593\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0803\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0869\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0593\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0803\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0869\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0593\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0803\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0869\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0592\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0803\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0869\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0592\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0803\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0869\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0592\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0802\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0869\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0591\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0802\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0868\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0591\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0802\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0868\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0591\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0802\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0868\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0591\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0801\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0868\n"
     ]
    }
   ],
   "source": [
    "acc1,acc2,acc3 = [],[],[]\n",
    "\n",
    "for k in range(1,51):\n",
    "    algo1 = KNNBaseline(k=k)\n",
    "    algo1.fit(train)\n",
    "    pred1 = algo1.test(test)\n",
    "    acc1.append(accuracy.rmse(pred1))\n",
    "    \n",
    "    algo2 = KNNWithMeans(k=k)\n",
    "    algo2.fit(train)\n",
    "    pred2 = algo2.test(test)\n",
    "    acc2.append(accuracy.rmse(pred2))\n",
    "    \n",
    "    algo3 = KNNWithZScore(k=k)\n",
    "    algo3.fit(train)\n",
    "    pred3 = algo3.test(test)\n",
    "    acc3.append(accuracy.rmse(pred3))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "71c4f929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0590937787561099\n",
      "1.080128771708165\n",
      "1.0868057393481272\n"
     ]
    }
   ],
   "source": [
    "print(min(acc1))\n",
    "print(min(acc2))\n",
    "print(min(acc3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "08f31f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "49\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "print(acc1.index(min(acc1)))\n",
    "print(acc2.index(min(acc2)))\n",
    "print(acc3.index(min(acc3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944a3a2b",
   "metadata": {},
   "source": [
    "### For all these three, k = 50 has the best RMSE. Since the best k is the max k in the parameter set, try to enlarge k and test the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9d38d0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0591\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0801\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0868\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0591\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0801\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0868\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0590\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0800\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0867\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0590\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0800\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0867\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0589\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0800\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0866\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0589\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0799\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0866\n"
     ]
    }
   ],
   "source": [
    "l = list(range(50,80,5))\n",
    "acc21,acc22,acc23 = [],[],[]\n",
    "for k in range(50,80,5):\n",
    "    algo1 = KNNBaseline(k=k)\n",
    "    algo1.fit(train)\n",
    "    pred1 = algo1.test(test)\n",
    "    acc21.append(accuracy.rmse(pred1))\n",
    "    \n",
    "    algo2 = KNNWithMeans(k=k)\n",
    "    algo2.fit(train)\n",
    "    pred2 = algo2.test(test)\n",
    "    acc22.append(accuracy.rmse(pred2))\n",
    "    \n",
    "    algo3 = KNNWithZScore(k=k)\n",
    "    algo3.fit(train)\n",
    "    pred3 = algo3.test(test)\n",
    "    acc23.append(accuracy.rmse(pred3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bafa8507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0589184038706616\n",
      "1.0799271512699997\n",
      "1.0866214464711343\n",
      "5\n",
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(min(acc21))\n",
    "print(min(acc22))\n",
    "print(min(acc23))\n",
    "print(acc21.index(min(acc21)))\n",
    "print(acc22.index(min(acc22)))\n",
    "print(acc23.index(min(acc23)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2ac5abd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad80980",
   "metadata": {},
   "source": [
    "### We can see, k = 75 has the best performance, but the difference is less than 0.3%.  Next part is an experiment for narrow down best k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "51fffb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0589\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0589\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0589\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0589\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0589\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0589\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0589\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0589\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0589\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0589\n"
     ]
    }
   ],
   "source": [
    "l3 = list(range(70,80))\n",
    "acc31 = []\n",
    "for k in range(70,80):\n",
    "    algo1 = KNNBaseline(k=k)\n",
    "    algo1.fit(train)\n",
    "    pred1 = algo1.test(test)\n",
    "    acc31.append(accuracy.rmse(pred1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c919bd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0588894944659317\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(min(acc31))\n",
    "print(acc31.index(min(acc31)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1e4d4227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l3[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0eb5530d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNBaseline on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0602  1.0592  1.0512  1.0623  1.0636  1.0593  0.0043  \n",
      "Fit time          0.93    0.91    0.97    0.93    0.92    0.93    0.02    \n",
      "Test time         1.36    1.40    1.36    1.32    1.39    1.37    0.03    \n"
     ]
    }
   ],
   "source": [
    "algo = KNNBaseline(k=75 )\n",
    "\n",
    "KNN_best = cross_validate(algo, data, measures=['RMSE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dd531f",
   "metadata": {},
   "source": [
    "### As expected, the best perfomance for KNN inspired algorithms are KNN baseline and the best K is around 75 and best RMSE is 1.0593"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a35eff",
   "metadata": {},
   "source": [
    "### CoClustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b98843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_cltr_u (int) â€“ Number of user clusters. Default is 3.\n",
    "# n_cltr_i (int) â€“ Number of item clusters. Default is 3.\n",
    "# n_epochs (int) â€“ Number of iteration of the optimization loop. Default is 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ebe419c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d4/s3dpbdr15qq9g4_2mn0lm1kc0000gn/T/ipykernel_13344/3284604495.py:12: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  algo.fit(train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0787\n",
      "RMSE: 1.0801\n",
      "RMSE: 1.0802\n",
      "RMSE: 1.0928\n",
      "RMSE: 1.0950\n",
      "RMSE: 1.0956\n",
      "RMSE: 1.0990\n",
      "RMSE: 1.0970\n",
      "RMSE: 1.1039\n",
      "RMSE: 1.1006\n",
      "RMSE: 1.1000\n",
      "RMSE: 1.1069\n",
      "RMSE: 1.1031\n",
      "RMSE: 1.1002\n",
      "RMSE: 1.1011\n",
      "RMSE: 1.1092\n",
      "RMSE: 1.1146\n",
      "RMSE: 1.1132\n",
      "RMSE: 1.1201\n",
      "RMSE: 1.1206\n",
      "RMSE: 1.1181\n",
      "RMSE: 1.1266\n",
      "RMSE: 1.1204\n",
      "RMSE: 1.1226\n",
      "RMSE: 1.1068\n",
      "RMSE: 1.1093\n",
      "RMSE: 1.1058\n",
      "RMSE: 1.1247\n",
      "RMSE: 1.1219\n",
      "RMSE: 1.1226\n",
      "RMSE: 1.1242\n",
      "RMSE: 1.1314\n",
      "RMSE: 1.1292\n",
      "RMSE: 1.1359\n",
      "RMSE: 1.1284\n",
      "RMSE: 1.1404\n",
      "RMSE: 1.1080\n",
      "RMSE: 1.1126\n",
      "RMSE: 1.1147\n",
      "RMSE: 1.1290\n",
      "RMSE: 1.1316\n",
      "RMSE: 1.1350\n",
      "RMSE: 1.1322\n",
      "RMSE: 1.1445\n",
      "RMSE: 1.1371\n",
      "RMSE: 1.1385\n",
      "RMSE: 1.1349\n",
      "RMSE: 1.1414\n"
     ]
    }
   ],
   "source": [
    "n_cltr_u  = [3,7,11,15]\n",
    "n_cltr_i = [3,7,11,15]\n",
    "n_epochs = [15, 20, 25]\n",
    "\n",
    "from itertools import product\n",
    "val = [n_cltr_u,n_cltr_i,n_epochs]\n",
    "para = []\n",
    "acc = []\n",
    "for i in product(*val):\n",
    "    para.append(i)\n",
    "    algo = CoClustering(n_cltr_u = i[0], n_cltr_i = i[1], n_epochs = i[2])\n",
    "    algo.fit(train)\n",
    "    pred = algo.test(test)\n",
    "    acc.append(accuracy.rmse(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "731c8ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0786870642272215"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3a60e6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 15)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para[acc.index(min(acc))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a66a54",
   "metadata": {},
   "source": [
    "### Move to smaller parameters due to the best result was at the smallest parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6e7f1092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d4/s3dpbdr15qq9g4_2mn0lm1kc0000gn/T/ipykernel_13344/1588292293.py:12: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  algo.fit(train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0483\n",
      "RMSE: 1.0483\n",
      "RMSE: 1.0483\n",
      "RMSE: 1.0483\n",
      "RMSE: 1.0483\n",
      "RMSE: 1.0483\n",
      "RMSE: 1.0483\n",
      "RMSE: 1.0483\n",
      "RMSE: 1.0483\n",
      "RMSE: 1.0483\n",
      "RMSE: 1.0483\n",
      "RMSE: 1.0483\n",
      "RMSE: 1.0665\n",
      "RMSE: 1.0665\n",
      "RMSE: 1.0663\n",
      "RMSE: 1.0735\n",
      "RMSE: 1.0712\n",
      "RMSE: 1.0725\n",
      "RMSE: 1.0483\n",
      "RMSE: 1.0483\n",
      "RMSE: 1.0483\n",
      "RMSE: 1.0724\n",
      "RMSE: 1.0754\n",
      "RMSE: 1.0754\n",
      "RMSE: 1.0737\n",
      "RMSE: 1.0694\n",
      "RMSE: 1.0805\n"
     ]
    }
   ],
   "source": [
    "n_cltr_u  = [1,2,3]\n",
    "n_cltr_i = [1,2,3]\n",
    "n_epochs = [10, 15, 20]\n",
    "\n",
    "from itertools import product\n",
    "val = [n_cltr_u,n_cltr_i,n_epochs]\n",
    "para = []\n",
    "acc = []\n",
    "for i in product(*val):\n",
    "    para.append(i)\n",
    "    algo = CoClustering(n_cltr_u = i[0], n_cltr_i = i[1], n_epochs = i[2])\n",
    "    algo.fit(train)\n",
    "    pred = algo.test(test)\n",
    "    acc.append(accuracy.rmse(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "de501535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 10)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para[acc.index(min(acc))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a7c66da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d4/s3dpbdr15qq9g4_2mn0lm1kc0000gn/T/ipykernel_13344/76367048.py:9: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  algo.fit(train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0483\n",
      "RMSE: 1.0483\n",
      "RMSE: 1.0483\n",
      "RMSE: 1.0483\n",
      "RMSE: 1.0483\n",
      "RMSE: 1.0483\n",
      "RMSE: 1.0483\n",
      "RMSE: 1.0483\n",
      "RMSE: 1.0483\n"
     ]
    }
   ],
   "source": [
    "n_epoch = list(range(1,10))\n",
    "\n",
    "from itertools import product\n",
    "val = [n_cltr_u,n_cltr_i,n_epochs]\n",
    "para = []\n",
    "acc = []\n",
    "for i in range(len(n_epoch)):\n",
    "    algo = CoClustering(n_cltr_u = 1, n_cltr_i = 1, n_epochs = n_epoch[i])\n",
    "    algo.fit(train)\n",
    "    pred = algo.test(test)\n",
    "    acc.append(accuracy.rmse(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "55b1d395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm CoClustering on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0492  1.0564  1.0489  1.0464  1.0583  1.0518  0.0046  \n",
      "Fit time          0.68    0.65    0.65    0.64    0.66    0.65    0.01    \n",
      "Test time         0.15    0.06    0.15    0.07    0.07    0.10    0.04    \n"
     ]
    }
   ],
   "source": [
    "algo = CoClustering(n_cltr_u = 1, n_cltr_i = 1, n_epochs = 10)\n",
    "\n",
    "SVDpp_best = cross_validate(algo, data, measures=['RMSE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4498b3",
   "metadata": {},
   "source": [
    "### The best RMSE for CoClustering is 1.0518 on 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5b551d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = pd.DataFrame({'Models':['SVD','SVD++','KNN Baseline','CoClustering'],'RMSE':[1.0144,1.0148 ,1.0593, 1.0518]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "43e2a994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 1.0, 'RMSE on different models')]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc = {'figure.figsize':(8,4)})\n",
    "sns.barplot(x = \"RMSE\",y = \"Models\", data = comp, color = \"pink\" ).set(title = \"RMSE on different models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c654832",
   "metadata": {},
   "source": [
    "# THE END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
